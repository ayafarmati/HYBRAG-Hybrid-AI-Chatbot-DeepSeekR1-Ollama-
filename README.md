# HYBRAG-Hybrid-AI-Chatbot-DeepSeekR1-Ollama-
# ğŸ¤– HYBRAG
## Hybrid RAG Chatbot powered by DeepSeek R1 & Ollama

HYBRAG est un **chatbot intelligent basÃ© sur une approche hybride**, combinant la **gÃ©nÃ©ration de texte par un modÃ¨le de langage (LLM)** et la **recherche sÃ©mantique dans des documents** grÃ¢ce au **RAG (Retrieval-Augmented Generation)**.

Lâ€™objectif du projet est de fournir des rÃ©ponses **fiables, contextualisÃ©es et basÃ©es sur des documents rÃ©els**, particuliÃ¨rement adaptÃ©es Ã  un **contexte acadÃ©mique**.

---

## âœ¨ FonctionnalitÃ©s

- ğŸ” CrÃ©ation de compte et connexion utilisateur
- ğŸ“„ Upload de documents pÃ©dagogiques (PDF, DOCX, PPT)
- ğŸ§  Indexation intelligente des documents (RAG)
- ğŸ” Recherche sÃ©mantique dans une base vectorielle
- ğŸ’¬ Chat interactif avec historique
- ğŸ“š RÃ©ponses basÃ©es sur les documents (avec sources optionnelles)
- âš¡ GÃ©nÃ©ration de rÃ©ponses en streaming

---

## ğŸ§  Approche Hybride (LLM + RAG)

HYBRAG ne repose pas uniquement sur un modÃ¨le de langage.

Il combine :
- **DeepSeek R1** pour la gÃ©nÃ©ration de rÃ©ponses
- **Un moteur de recherche documentaire** basÃ© sur des embeddings

Cette approche hybride permet de :
- rÃ©duire les hallucinations du modÃ¨le
- amÃ©liorer la pertinence des rÃ©ponses
- garantir un lien direct avec les documents fournis

---

## ğŸ—ï¸ Architecture Globale
![Architecture du Chatbot](assets/architecture.png)



---

## ğŸ“„ Pipeline dâ€™Indexation des Documents

1. Upload du fichier par lâ€™utilisateur
2. DÃ©tection du type de fichier (PDF / DOCX / PPT)
3. Extraction du texte brut
4. DÃ©coupage en chunks  
   - Taille : **1000 caractÃ¨res**
   - Overlap : **200 caractÃ¨res**
5. GÃ©nÃ©ration des embeddings avec **Ollama**
6. Stockage dans **ChromaDB**
7. Indexation et sauvegarde

---

## â“ Pipeline Question / RÃ©ponse (RAG)

1. Lâ€™utilisateur pose une question
2. DÃ©tection des questions simples (smalltalk)
3. Recherche sÃ©mantique dans ChromaDB
4. Filtrage par score de pertinence
5. Construction du contexte (Top-K chunks)
6. GÃ©nÃ©ration de la rÃ©ponse par DeepSeek R1
7. Retour de la rÃ©ponse en streaming

---

## ğŸ§° Technologies UtilisÃ©es

### Backend
- **FastAPI** (Python)
- WebSocket (chat temps rÃ©el)

### Frontend
- HTML
- CSS
- JavaScript

### Intelligence Artificielle
- **DeepSeek R1** (LLM)
- **Ollama** (embeddings)
- **ChromaDB** (base vectorielle)
- RAG (Retrieval-Augmented Generation)

### DonnÃ©es
- Base de donnÃ©es relationnelle (utilisateurs, conversations)
- Base vectorielle (documents indexÃ©s)

---

## ğŸš€ Lancer le Projet

```bash
# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows : venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer le backend
uvicorn main:app --reload


